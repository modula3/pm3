\section{xReal64: 64-bit IEEE Reals}
\subsection{Types}
Why rename LONGREAL?  Because numerical analysis is tuned to specific
resolutions for specific classes of problems.  If you need a 64-bit real
to do a job, you'd better be sure that is exactly what you are getting.
Of course the language definition says that is the meaning of LONGREAL,
but why trust it over time?  Maybe Modula-4 will use LONGREAL for
the 80-bit reals.  By using REAL64, we get to fix it one place.
Of course, with structural equivalence, you can still intermingle
LONGREAL as desired.

A minor point:  Since these routines do not lend themselves to
generics, using REAL64 and REAL32 makes it fairly easy to clone
a 64-bit routine and generate a 32-bit version.  One still has to
convert the remaining literals from ``D'' to ``E''.

\subsection{Constants}
These are largely taken from Math.i3 and CRC91.
We added others as needed when trying
to eliminate literals from routines.

\subsection{Math.i3 Functions}
Why redirect them to here?  Because Math.i3 is inadequate, and
Real64 can serve as a replacement.

\subsection{Other Functions}
\subsection*{sgn}
The signum function is occasionally handy.  However, for
performance purpose, you usually have to do it inline.

\subsection{Special Functions}
These are implemented in xSpecFtn,m3 but exported via xReal64.i3.

\subsection*{factorial}
Following NR92, this is implemented with a cached table for
$0! \dots 34!$.
Originally 34 was chosen because it could be handled by
REAL32.  Having moved to REAL64, we could extend the
table, but see no need.  Beyond $34!$ we use the $\Gamma$ function.

\subsection*{ln\_factorial}
This one needs a cache also, but it can't be a
CONST [HGG: At least, I'm not willing to build it].  So we need a VAR
cache, which means it could be in global space, in NT-thread
space, or in an object.  Since all threads should agree on
the table values, I'll go global space.  However, this
assumes that assigning a real to a table cell is an atomic
action.  Seems like a safe assumption for me.

How big should the cache be?  We typically use ln\_factorial when
factorial overflows.  That goes to $34!$, so the cache better be bigger
than 34.  On the
other hand, too big a cache takes extra room (hey, this is
Modula-3, so who cares about that? :-), and it takes extra
initialization on the startup.  We notice that $70!$ is 1
googol, so that seems a handy cutoff.  [HGG: Personally, I've
never run into a problem using googols.]


\subsection*{gamma, ln\_gamma}
The basic idea is to implement Stirling's formula for gamma(n+1).
That is described in Grah81, pg 112, and in
CRC91, pg 351.  CRC91 has the most complete treatment:
\begin{equation}
  \Gamma(x+1)=\sqrt{2\pi x}x^{x}e^{-x}(1+\frac{1}{12x}
    +\frac{1}{288x^2}+\dots)
\end{equation}

However, for numerical analysis, Lanczos (cited in NR92, pg 213, 6.1.5,)
provides a better approximation:
\begin{equation}
  \Gamma(z+1)=(z+ \gamma +1/2)^{z+1/2}e^{-(z+ \gamma +1/2)}
  \sqrt{2\pi}*(c_0+\frac{c_1}{z+1}+\frac{c_2}{z+2}
       +\cdots+\frac{c_N}{z+N}+\epsilon)\ (z>0)
\end{equation}

With all these exponentials and multiplies, the obvious implementation
is to work in logs.  As NR92 notes, $\Gamma$ is typically used
in multiply and divide situations, leading to normal (small) numbers.
So it makes sense to get ln\_gamma, and then get other functions from that.

The exponential needs work.  First, there
is a repeated factor $x=z+\gamma+0.5$.  Second, since we are
returning ln, we really want:
\begin{equation}
  \ln(x)(z+1/2)(-x)+\ln(\sqrt{2\pi})+\ln(\mbox{series})
\end{equation}
This simplifies to:
\begin{equation}
  \ln(x)*(z+1/2)+(-x)+0.918938533204673+\ln(\mbox{series})
\end{equation}
[HGG: I got the $0.918\ldots $ number from MathCad.]

NR92 handles the coeffs in a loop.  We have unrolled the loop here.

\subsection*{gamma\_p, gamma\_q}
Incomplete Gamma Functions.  Per Krey88, pg A78:
\begin{eqnarray}
 \Gamma(a) & =& P(a,x) + Q(a,x)\\
 P(a,x) & = & \int_0^x e^{-t}t^{a-1}dt\\
 Q(a,x) & = & \int_x^\infty e^{-t}t^{a-1}\,dt
\end{eqnarray}
NR92, pg 216, also gives:
\begin{eqnarray}
  P(a,x) & = & \frac{\gamma (a,x)}{\Gamma (a)}\\
  Q(a,x) & = & \frac{\Gamma (a,x)}{\Gamma (a)}\\
         & = & \frac{1}{\Gamma(a)} \int_x^\infty e^{-t}t^{a-1}\,dt
\end{eqnarray}
In other words, NR92's $Q$ is Krey88's $Q/\Gamma$.  We will use 
NR92's treatment, because it leads to the useful:
\begin{equation}
  Q(a,x) = 1 - P(a,x)
\end{equation}
This is helpful because depending on the ratio of a and x, Q or P could
be the better mechanism for computation.  That is, Q is flat when 
x is small compared to a, and P is flat when x is large compared to a.
Either case makes numerical analysis difficult.  So we will choose
via the criteria given by NR92:
\begin{verbatim}
     if x<(a+1) then
          use P approach
     else
          use Q approach
     end
\end{verbatim}

The next problem is of course to determine the $\gamma(a,x)$ for P and
the $\Gamma(a,x)$ for Q.  NR92, pg 217, provides a series approximation
for $\gamma(a,x)$ and a continued fraction approximation
for $\Gamma(a,x)$. These deserve helper functions of their own.
While we have used the same
names for these functions (gamser for the series and gamcf for the
continued fraction), these are original implementations.


\subsubsection*{gamser}
\begin{equation}
  \gamma(a,x) = e^{-x}x^a\sum_{n=0}^\infty
                    \frac{\Gamma(a)}{\Gamma(a+1+n)}x^n
\end{equation}
The initial factor can be captured as follows, using ln\_gamma(a)
which we pass as lga:
\begin{verbatim}
    factor= exp(-lga-x+a*log(x))
\end{verbatim}
Next, we need to iterate the series to convergence.  How
converged?  We will go until the absolute value of the last
term is less than eps=5*EPS.

Notice that each additional term can be produced by multiplying the
previous term:
\begin{verbatim}
  term[i+1]=term[i]*x/(a+1+i)
\end{verbatim}

To initialize this, we can do the zeroth term by hand, then
start iterating.  Note that in the each term,
$\Gamma(a)/\Gamma(a+1)$ cancels to $1/a$.  In the zeroth term that
is it.  In later terms, we need $(a+1)(a+1+1)(a+1+2)\dots$ in
the denominator.  The $(a+1+n)$ item, called a1n, is
initialized to $a+1.0$.  For the x's, we start with $x^0=1$, and
then multiply x's onto the term
\begin{verbatim}
     term:=1.0/a;
     sum:=term;
     a1n:=a;
     FOR i:=1 TO MaxIter DO
          a1n:=a1n+1.0;
          term:=term*x/a1n;
          sum:=sum+term;
          IF ABS(term)<eps THEN
               RETURN factor*sum
          END;
     END;
\end{verbatim}

\subsubsection*{gamcf}
\begin{equation}
  \Gamma(a,x) = e^{-x}x^a \left(
                    \frac{1}{\displaystyle x+1-a 
                    - \frac{1\cdot(1-a)}{\displaystyle x+3-a
                      - \frac{2\cdot(2-a)}{\displaystyle x+5-a
                        - \cdots}}}
                    \right)
\end{equation}
Continued fractions are tedious to set up.
We start by copying the betacf code and then
working out the new meanings of the variables here:

We need to use n in the calculations, so we need to track the
iterator with a real, call it m.
\begin{verbatim}
     m[j]=m[j-1]+1.0
     b[j]=m*(m-a);  b[0]=0 so actually start with b[0]=tiny;
     b[1]=1
     a[j]=a[j-1]+2.0;  a[1]=x+1.0-a
     the global TINY will work here
     eps=5.0e-7
     MaxIter=90
\end{verbatim}
     
The initialization conditions are so odd, I decided to set
up a[1], b[1] by hand, and then update them at the end of
the loop.
\begin{verbatim}
j=0:
     b0=0
     f=b0=0 ==> f=TINY
     C=f=TINY
     D=0
j=1:
     bj=x+1-a
     aj=1
     D=bj+aj*D=bj=x+1+a
     C=bj+aj/C=x+1+a+1/TINY
     D=1/D=1/(x+1+a)
     delta=C*D=(x+1+a+1/TINY)/(x+1+a)
     f=f*delta=TINY*(x+1+a+1/TINY)/(x+1+a)
          =(x*TINY+1*TINY+a*TINY+1)/(x+1+a)
          = approx 1/(x+1+a) = D
j>=2:
     m=m+1; m2p1=2*m+1
     bj=x+m2p1-a
     aj=m*(m-a)
\end{verbatim}
We can turn m2p1 into an add: m2p1:=m2p1+2.0.  We can turn x-
a into a precalc: xa:=x-a.  Then, with m=0 and m2p1=1 at the
start:
\begin{verbatim}
     m:=m+1.0; m2p1:=m2p1+2.0;
     by:=xa+m2p1;
     aj:=-m*(m-a);
\end{verbatim}

Next, I see I actually need that x-a business in the
initialization, so I can skip the m2p1 stuff and just do
\begin{verbatim}
     init: m:=0.0; xa:=x+1-a
     m:=m+1.0; xa:=xa+2.0;
\end{verbatim}

Then I see that aj=-m*(m-a)=m*(a-m).  I'm not sure if the
compiler would have caught that, so I'll do it here.  But it
is a bit obscure, so folks better read this note before
fooling with it.


\subsection*{binomial}
The formula is:
\begin{equation}
  {n \choose k} = \frac{n!}{k!(n-k)!}
\end{equation}

Even if we weren't doing factorials, we would
probably want to do a divide and a multiply as logs.  So the
formula becomes:
\begin{equation}
  \exp(\ln(n!)-\ln(k!)-\ln((n-k)!))
\end{equation}
Since we already have ln\_factorial, we can use that and just take
the exponential at the end.

\subsection*{beta}
The standard formula is:
\begin{equation}
  B(z,w) = \frac{\Gamma(z) \Gamma(w)}{\Gamma(z+w)}
\end{equation}
However, we implement using logs, which means we can use ln\_gamma.

\subsection*{betai}
According to NR92, pp 226-227,
the incomplete beta function is defined as:
\begin{eqnarray}
    I_x(a,b) & = & \frac{B_x(a,b)}{B(a,b)}
               = \frac{1}{B(a,b)}\int_0^xt^{a-1}(1-t)^{b-1}dt\\
             & = & 1 - I_{1-x}(b,a)
\end{eqnarray}

NR92 provides both a series and a continued fraction approximation,
and states the continued fraction approach is good for
$x < (a+1)/(a+b+2)$.  For cases where this does not hold, NR92
recommends using the $I_{1-x}$ formula.  The continued fraction
form is:
\begin{eqnarray}
  I_x(a,b) & = & \frac{x^a(1-x)^b}{aB(a,b)}
                 \left[ \frac{1}{\displaystyle 1
                        + \frac{d_1} {\displaystyle 1
                          + \frac{d_2} {displaystyle 1
                            + \cdots}}} \right]\\
  d_{2m+1} & = & -\frac{(a+m)(a+b+m)x} {(a+2m)(a+2m+1)}\\
  d_{2m}   & = & \frac{m(b-m)x}{(a+2m-1)(a+2m)}
\end{eqnarray}
  
The initial factor needs to be
calculated using $B(a,b),x$ or $B(b,a),1-x$, depending on the convergence
condition:
\begin{verbatim}
     if x < (a+1)/(a+b+2) then
          factor = x^a*(1-x)^b)/(a*beta(a,b))
     else
          factor = (1-x)^b*(1-(1-x))^a/(b*beta(b,a))
     end
\end{verbatim}

Notice that $\mbox{beta}(b,a)=\mbox{beta}(a,b)$, 
and that $(1-(1-x))^a = x^a$.
So the two forms are the same except for dividing by a vs b.
So let's make the factor just the common part:
\begin{equation}
  \mbox{factor} = (1-x)^b*x^a/\mbox{beta}(a,b)
\end{equation}
This has lots of exps and muls, so we use log forms:
\begin{equation}
  \mbox{factor} = \exp(a \cdot \ln(x)+b \cdot \ln(1.0-x)
      -\ln(\mbox{beta}(a,b)))
\end{equation}
But notice that beta is already an exp function.  So we can
use the raw form and save some calls and calcs:
\begin{equation}
  \mbox{factor} = \exp(a \cdot \ln(x) + b \cdot \ln(1.0-x)
          -(\mbox{ln\_gamma}(a)+\mbox{ln\_gamma}(b)-\mbox{ln\_gamma}(a+b))
\end{equation}

For the second part of the equation, we follow NR92's lead
in using the continued fraction approach.   And we use the recommended
modified Lentz (NR92, pg 172).  

Lentz is a bit tricky.
To avoid using b for both the ftn
parameter, and the Lentz b[j] item, we change the Lenz
a's to aj and the Lentz b's to bj.  That makes it much
cleaner.  Because the iteration variable is lost after a
loop completes, we return f directly when found,
and raise the error if we actually complete the loop.
\begin{verbatim}
     f=b0=0, so make f=TINY
     C=f
     D=0
     b[0]=0; b[j>0]= 1
     a[0]=1; a[1]=1; a[2m+1>1]=d1; a[2m>1]=d2
\end{verbatim}

We have a tricky initialization for j=0,1,2 and
then get rolling with j=3.  That suggests doing the j0,j1
cases by hand and then starting the loop with j=2.  That
would be done with a loop on i=1 to Max, with m=2*i and then
m=2*i+1 for the pair.
\begin{verbatim}
j=0:
     b0=0
     f=b0=0, so f=TINY
     C=f=TINY
     D=0
j=1:
     aj=1
     bj=1
     D=bj+aj*D=1+TINY
     C=bj+aj/C=1+1/TINY
     D=1/D=1/(1+TINY)= approx 1
     delta=C*D=C*1=C=1+1/TINY=very large
     f=f*delta=TINY(1+1/TINY)=TINY+1= approx 1
j=2:
     j=2 is equiv of d1, so the d[2m+1) formula applies,
     using m=0
     aj=-(a+0)*(a+b+m)*x/((a+2*0)*(a+2*0+1))=-
     a*(a+b)*x/(a*(a+1))
          =-(a+b)*x/(a+1)
     bj=1
     D=bj+aj*D=1+aj*1=1+aj
     C=bj+aj/C=1+aj/(very large)=1+aj*TINY=approx 1
     D=1/D=1/(1+aj)
     delta=C*D=1*(1/(1+aj))=1/(1+aj)
     f=f*delta=1/(1+aj) = D
\end{verbatim}
These are the actual initialization values.  After that we
can begin the normal 2m, 2m+1 cycle.


\subsection*{erf,erfc}
NR92, pg 220, provides:
\begin{eqnarray}
  \mbox{erf}(x)  & = & P\left( \frac{1}{2},x^2 \right) \, (x \ge 0)\\
  \mbox{erf}(-x) & = & -\mbox{erf}(x)\\
  \mbox{erfc}(x) & = & Q\left( \frac{1}{2},x^2 \right) \, (x \ge 0)\\
  \mbox{erfc}(-x) & = & 2-\mbox{erfc}(x) 
\end{eqnarray}
We implement these as is. 

